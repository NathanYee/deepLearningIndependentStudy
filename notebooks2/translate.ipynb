{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translation files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "French/English parallel texts from http://www.statmt.org/wmt15/translation-task.html .  It was created by Chris Callison-Burch, who crawled millions of web pages and then used *a set of simple heuristics to transform French URLs onto English URLs (i.e. replacing \"fr\" with \"en\" and about 40 other hand-written rules), and assume that these documents are translations of each other*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path('data/translate')\n",
    "TMP_PATH = PATH/'tmp'\n",
    "TMP_PATH.mkdir(exist_ok=True)\n",
    "fname='giga-fren.release2.fixed'\n",
    "en_fname = PATH/f'{fname}.en'\n",
    "fr_fname = PATH/f'{fname}.fr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_eq = re.compile('^(Wh[^?.!]+\\?)')\n",
    "re_fq = re.compile('^([^?.!]+\\?)')\n",
    "\n",
    "lines = ((re_eq.search(eq), re_fq.search(fq)) \n",
    "         for eq, fq in zip(open(en_fname, encoding='utf-8'), open(fr_fname, encoding='utf-8')))\n",
    "\n",
    "qs = [(e.group(), f.group()) for e,f in lines if e and f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(qs, (PATH/'fr-en-qs.pkl').open('wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs = pickle.load((PATH/'fr-en-qs.pkl').open('rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs[:5], len(qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_qs,fr_qs = zip(*qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_tok = Tokenizer.proc_all_mp(partition_by_cores(en_qs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_tok = Tokenizer.proc_all_mp(partition_by_cores(fr_qs), 'fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_tok[0], fr_tok[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.percentile([len(o) for o in en_tok], 90), np.percentile([len(o) for o in fr_tok], 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep = np.array([len(o)<30 for o in en_tok])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_tok = np.array(en_tok)[keep]\n",
    "fr_tok = np.array(fr_tok)[keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(en_tok, (PATH/'en_tok.pkl').open('wb'))\n",
    "pickle.dump(fr_tok, (PATH/'fr_tok.pkl').open('wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_tok = pickle.load((PATH/'en_tok.pkl').open('rb'))\n",
    "fr_tok = pickle.load((PATH/'fr_tok.pkl').open('rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def toks2ids(tok,pre):\n",
    "    freq = Counter(p for o in tok for p in o)\n",
    "    itos = [o for o,c in freq.most_common(40000)]\n",
    "    itos.insert(0, '_bos_')\n",
    "    itos.insert(1, '_pad_')\n",
    "    itos.insert(2, '_eos_')\n",
    "    itos.insert(3, '_unk')\n",
    "    stoi = collections.defaultdict(lambda: 3, {v:k for k,v in enumerate(itos)})\n",
    "    ids = np.array([([stoi[o] for o in p] + [2]) for p in tok])\n",
    "    np.save(TMP_PATH/f'{pre}_ids.npy', ids)\n",
    "    pickle.dump(itos, open(TMP_PATH/f'{pre}_itos.pkl', 'wb'))\n",
    "    return ids,itos,stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_ids,en_itos,en_stoi = toks2ids(en_tok,'en')\n",
    "fr_ids,fr_itos,fr_stoi = toks2ids(fr_tok,'fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ids(pre):\n",
    "    ids = np.load(TMP_PATH/f'{pre}_ids.npy')\n",
    "    itos = pickle.load(open(TMP_PATH/f'{pre}_itos.pkl', 'rb'))\n",
    "    stoi = collections.defaultdict(lambda: 3, {v:k for k,v in enumerate(itos)})\n",
    "    return ids,itos,stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_ids,en_itos,en_stoi = load_ids('en')\n",
    "fr_ids,fr_itos,fr_stoi = load_ids('fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[fr_itos[o] for o in fr_ids[0]], len(en_itos), len(fr_itos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fasttext word vectors available from https://fasttext.cc/docs/en/english-vectors.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install git+https://github.com/facebookresearch/fastText.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastText as ft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the fastText library, you'll need to download [fasttext word vectors](https://github.com/facebookresearch/fastText/blob/master/pretrained-vectors.md) for your language (download the 'bin plus text' ones)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vecs(lang, ft_vecs):\n",
    "    vecd = {w:ft_vecs.get_word_vector(w) for w in ft_vecs.get_words()}\n",
    "    pickle.dump(vecd, open(PATH/f'wiki.{lang}.pkl','wb'))\n",
    "    return vecd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_vecs = ft.load_model(str((PATH/'wiki.en.bin')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_vecd = get_vecs('en', en_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_vecs = ft.load_model(str((PATH/'wiki.fr.bin')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_vecd = get_vecs('fr', fr_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_vecd = pickle.load(open(PATH/'wiki.en.pkl','rb'))\n",
    "fr_vecd = pickle.load(open(PATH/'wiki.fr.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ft_words = ft_vecs.get_words(include_freq=True)\n",
    "# ft_word_dict = {k:v for k,v in zip(*ft_words)}\n",
    "# ft_words = sorted(ft_word_dict.keys(), key=lambda x: ft_word_dict[x])\n",
    "\n",
    "# len(ft_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 300)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_en_vec = len(en_vecd[','])\n",
    "dim_fr_vec = len(fr_vecd[','])\n",
    "dim_en_vec,dim_fr_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0075652334, 0.29283327)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_vecs = np.stack(list(en_vecd.values()))\n",
    "en_vecs.mean(),en_vecs.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29, 33)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enlen_90 = int(np.percentile([len(o) for o in en_ids], 99))\n",
    "frlen_90 = int(np.percentile([len(o) for o in fr_ids], 97))\n",
    "enlen_90,frlen_90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_ids_tr = np.array([o[:enlen_90] for o in en_ids])\n",
    "fr_ids_tr = np.array([o[:frlen_90] for o in fr_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqDataset(Dataset):\n",
    "    def __init__(self, x, y): self.x,self.y = x,y\n",
    "    def __getitem__(self, idx): return A(self.x[idx], self.y[idx])\n",
    "    def __len__(self): return len(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45219, 5041)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "trn_keep = np.random.rand(len(en_ids_tr))>0.1\n",
    "en_trn,fr_trn = en_ids_tr[trn_keep],fr_ids_tr[trn_keep]\n",
    "en_val,fr_val = en_ids_tr[~trn_keep],fr_ids_tr[~trn_keep]\n",
    "len(en_trn),len(en_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_ds = Seq2SeqDataset(fr_trn,en_trn)\n",
    "val_ds = Seq2SeqDataset(fr_val,en_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_samp = SortishSampler(en_trn, key=lambda x: len(en_trn[x]), bs=bs)\n",
    "val_samp = SortSampler(en_val, key=lambda x: len(en_val[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_dl = DataLoader(trn_ds, bs, transpose=True, transpose_y=True, num_workers=1, \n",
    "                    pad_idx=1, pre_pad=False, sampler=trn_samp)\n",
    "val_dl = DataLoader(val_ds, int(bs*1.6), transpose=True, transpose_y=True, num_workers=1, \n",
    "                    pad_idx=1, pre_pad=False, sampler=val_samp)\n",
    "md = ModelData(PATH, trn_dl, val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(33, 29), (33, 27), (33, 28), (25, 11), (33, 18)]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "it = iter(trn_dl)\n",
    "its = [next(it) for i in range(5)]\n",
    "[(len(x),len(y)) for x,y in its]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_emb(vecs, itos, em_sz):\n",
    "    \"\"\"\n",
    "    we create a special embedding function as we want to use the fasttext weights\n",
    "    \n",
    "    vecs: word to vector dictionary\n",
    "    itos: ordered list of words\n",
    "    em_sz: size of embedding\n",
    "    \"\"\"\n",
    "    emb = nn.Embedding(len(itos), em_sz, padding_idx=1)\n",
    "    wgts = emb.weight.data # modifying wgts will modify emb.weight.data\n",
    "    miss = []\n",
    "    # i:index, w:word\n",
    "    for i,w in enumerate(itos):\n",
    "        try: wgts[i] = torch.from_numpy(vecs[w]*3)\n",
    "        except: miss.append(w)\n",
    "    print(len(miss),miss[5:10])\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "nh,nl = 256,2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqRNN(nn.Module):\n",
    "    def __init__(self, vecs_enc, itos_enc, em_sz_enc, vecs_dec, itos_dec, em_sz_dec, nh, out_sl, nl=2):\n",
    "        \"\"\"\n",
    "        enc: input language (fr)\n",
    "        dec: output language (en)\n",
    "        nh: size of hidden state\n",
    "        out_sl: output sequence length (longest sequence in the output language (en))\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.nl,self.nh,self.out_sl = nl,nh,out_sl\n",
    "        self.emb_enc = create_emb(vecs_enc, itos_enc, em_sz_enc)\n",
    "        self.emb_enc_drop = nn.Dropout(0.15)\n",
    "        self.gru_enc = nn.GRU(em_sz_enc, nh, num_layers=nl, dropout=0.25)\n",
    "        self.out_enc = nn.Linear(nh, em_sz_dec, bias=False)\n",
    "        \n",
    "        self.emb_dec = create_emb(vecs_dec, itos_dec, em_sz_dec)\n",
    "        self.gru_dec = nn.GRU(em_sz_dec, em_sz_dec, num_layers=nl, dropout=0.1)\n",
    "        self.out_drop = nn.Dropout(0.35)\n",
    "        self.out = nn.Linear(em_sz_dec, len(itos_dec))\n",
    "        self.out.weight.data = self.emb_dec.weight.data\n",
    "        \n",
    "    def forward(self, inp):\n",
    "        sl, bs = inp.size() # sequence length, batch size\n",
    "        \n",
    "        # initialize hidden state\n",
    "        h = self.initHidden(bs)\n",
    "        \n",
    "        # use rnn to create enc state (h)\n",
    "        emb = self.emb_enc_drop(self.emb_enc(inp))\n",
    "        enc_out, h = self.gru_enc(emb, h)\n",
    "        h = self.out_enc(h)\n",
    "        \n",
    "        # decode the hidden state to generate sequence\n",
    "        dec_inp = V(torch.zeros(bs).long()) \n",
    "        res = []\n",
    "        for i in range(self.out_sl):\n",
    "            emb = self.emb_dec(dec_inp).unsqueeze(0) # we are making our own loop for the rnn so fix dimensions\n",
    "            outp, h = self.gru_dec(emb, h)\n",
    "            outp = self.out(self.out_drop(outp[0]))\n",
    "            res.append(outp) # log probabilities of size vocab\n",
    "            \n",
    "            # use highest probability character to feed into next step\n",
    "            dec_inp = V(outp.data.max(1)[1]) # why is this max of 1\n",
    "            \n",
    "            # check if all the next characters are padding _pad_\n",
    "            if (dec_inp==1).all(): break\n",
    "        return torch.stack(res)\n",
    "        \n",
    "    def initHidden(self, bs): return V(torch.zeros(self.nl, bs, self.nh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2seq_loss(input, target):\n",
    "    sl,bs = target.size()\n",
    "    sl_in,bs_in,nc = input.size()\n",
    "    if sl>sl_in: input = F.pad(input, (0,0,0,0,0,sl-sl_in))\n",
    "    input = input[:sl]\n",
    "    return F.cross_entropy(input.view(-1,nc), target.view(-1))#, ignore_index=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_fn = partial(optim.Adam, betas=(0.8, 0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3097 ['l’', \"d'\", 't_up', 'd’', \"qu'\"]\n",
      "1285 [\"'s\", '’s', \"n't\", 'n’t', ':']\n"
     ]
    }
   ],
   "source": [
    "rnn = Seq2SeqRNN(fr_vecd, fr_itos, dim_fr_vec, en_vecd, en_itos, dim_en_vec, nh, enlen_90)\n",
    "learn = RNN_Learner(md, SingleModel(to_gpu(rnn)), opt_fn=opt_fn)\n",
    "learn.crit = seq2seq_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3aa95fe7551a4ccdb7c1f7f7e9115ed9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 12/302 [00:02<00:52,  5.50it/s, loss=13.4]\n",
      " 67%|██████▋   | 202/302 [00:36<00:18,  5.55it/s, loss=37]  "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find()\n",
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=3e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f4ca6cb258047f4a0cc0ff4695e658b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=12), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 41/302 [00:07<00:46,  5.59it/s, loss=8.9] \n",
      "epoch      trn_loss   val_loss                              \n",
      "    0      5.662628   5.714037  \n",
      "    1      5.012479   4.973389                              \n",
      "    2      4.135276   4.450971                              \n",
      "    3      3.761769   4.068193                              \n",
      "    4      3.568051   3.95978                               \n",
      "    5      3.505596   3.749948                              \n",
      "    6      3.297563   3.684398                              \n",
      "    7      3.458026   3.567881                              \n",
      "    8      3.043173   3.55637                               \n",
      "    9      2.975676   3.514382                              \n",
      "    10     3.168161   3.467236                              \n",
      "    11     2.897166   3.482096                              \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([3.4821])]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(lr, 1, cycle_len=12, use_clr=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('initial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('initial')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x,y = next(iter(val_dl))\n",
    "probs = learn.model(V(x))\n",
    "preds = to_np(probs.max(2)[1])\n",
    "\n",
    "for i in range(10,20):\n",
    "    print(' '.join([fr_itos[o] for o in x[:,i] if o != 1]))\n",
    "    print(' '.join([en_itos[o] for o in y[:,i] if o != 1]))\n",
    "    print(' '.join([en_itos[o] for o in preds[:,i] if o!=1]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Bidir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Seq2SeqRNN_Bidir(nn.Module):\n",
    "    def __init__(self, vecs_enc, itos_enc, em_sz_enc, vecs_dec, itos_dec, em_sz_dec, nh, out_sl, nl=2):\n",
    "        super().__init__()\n",
    "        self.emb_enc = create_emb(vecs_enc, itos_enc, em_sz_enc)\n",
    "        self.nl,self.nh,self.out_sl = nl,nh,out_sl\n",
    "        self.gru_enc = nn.GRU(em_sz_enc, nh, num_layers=nl, dropout=0.25, bidirectional=True)\n",
    "        self.out_enc = nn.Linear(nh*2, em_sz_dec, bias=False)\n",
    "        self.drop_enc = nn.Dropout(0.05)\n",
    "        self.emb_dec = create_emb(vecs_dec, itos_dec, em_sz_dec)\n",
    "        self.gru_dec = nn.GRU(em_sz_dec, em_sz_dec, num_layers=nl, dropout=0.1)\n",
    "        self.emb_enc_drop = nn.Dropout(0.15)\n",
    "        self.out_drop = nn.Dropout(0.35)\n",
    "        self.out = nn.Linear(em_sz_dec, len(itos_dec))\n",
    "        self.out.weight.data = self.emb_dec.weight.data\n",
    "        \n",
    "    def forward(self, inp):\n",
    "        sl,bs = inp.size()\n",
    "        h = self.initHidden(bs)\n",
    "        emb = self.emb_enc_drop(self.emb_enc(inp))\n",
    "        enc_out, h = self.gru_enc(emb, h)\n",
    "        h = h.view(2,2,bs,-1).permute(0,2,1,3).contiguous().view(2,bs,-1)\n",
    "        h = self.out_enc(self.drop_enc(h))\n",
    "\n",
    "        dec_inp = V(torch.zeros(bs).long())\n",
    "        res = []\n",
    "        for i in range(self.out_sl):\n",
    "            emb = self.emb_dec(dec_inp).unsqueeze(0)\n",
    "            outp, h = self.gru_dec(emb, h)\n",
    "            outp = self.out(self.out_drop(outp[0]))\n",
    "            res.append(outp)\n",
    "            dec_inp = V(outp.data.max(1)[1])\n",
    "            if (dec_inp==1).all(): break\n",
    "        return torch.stack(res)\n",
    "    \n",
    "    def initHidden(self, bs): return V(torch.zeros(self.nl*2, bs, self.nh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rnn = Seq2SeqRNN_Bidir(fr_vecd, fr_itos, dim_fr_vec, en_vecd, en_itos, dim_en_vec, nh, enlen_90)\n",
    "learn = RNN_Learner(md, SingleModel(to_gpu(rnn)), opt_fn=opt_fn)\n",
    "learn.crit = seq2seq_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "learn.fit(lr, 1, cycle_len=12, use_clr=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.save('bidir')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teacher forcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqStepper(Stepper):\n",
    "    def step(self, xs, y, epoch):\n",
    "        self.m.pr_force = (10-epoch)*0.1 if epoch<10 else 0\n",
    "        xtra = []\n",
    "        output = self.m(*xs, y)\n",
    "        if isinstance(output,tuple): output,*xtra = output\n",
    "        self.opt.zero_grad()\n",
    "        loss = raw_loss = self.crit(output, y)\n",
    "        if self.reg_fn: loss = self.reg_fn(output, xtra, raw_loss)\n",
    "        loss.backward()\n",
    "        if self.clip:   # Gradient clipping\n",
    "            nn.utils.clip_grad_norm(trainable_params_(self.m), self.clip)\n",
    "        self.opt.step()\n",
    "        return raw_loss.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqRNN_TeacherForcing(nn.Module):\n",
    "    def __init__(self, vecs_enc, itos_enc, em_sz_enc, vecs_dec, itos_dec, em_sz_dec, nh, out_sl, nl=2):\n",
    "        super().__init__()\n",
    "        self.emb_enc = create_emb(vecs_enc, itos_enc, em_sz_enc)\n",
    "        self.nl,self.nh,self.out_sl = nl,nh,out_sl\n",
    "        self.gru_enc = nn.GRU(em_sz_enc, nh, num_layers=nl, dropout=0.25)\n",
    "        self.out_enc = nn.Linear(nh, em_sz_dec, bias=False)\n",
    "        self.emb_dec = create_emb(vecs_dec, itos_dec, em_sz_dec)\n",
    "        self.gru_dec = nn.GRU(em_sz_dec, em_sz_dec, num_layers=nl, dropout=0.1)\n",
    "        self.emb_enc_drop = nn.Dropout(0.15)\n",
    "        self.out_drop = nn.Dropout(0.35)\n",
    "        self.out = nn.Linear(em_sz_dec, len(itos_dec))\n",
    "        self.out.weight.data = self.emb_dec.weight.data\n",
    "        self.pr_force = 1.\n",
    "        \n",
    "    def forward(self, inp, y=None):\n",
    "        sl,bs = inp.size()\n",
    "        h = self.initHidden(bs)\n",
    "        emb = self.emb_enc_drop(self.emb_enc(inp))\n",
    "        enc_out, h = self.gru_enc(emb, h)\n",
    "        h = self.out_enc(h)\n",
    "\n",
    "        dec_inp = V(torch.zeros(bs).long())\n",
    "        res = []\n",
    "        for i in range(self.out_sl):\n",
    "            emb = self.emb_dec(dec_inp).unsqueeze(0)\n",
    "            outp, h = self.gru_dec(emb, h)\n",
    "            outp = self.out(self.out_drop(outp[0]))\n",
    "            res.append(outp)\n",
    "            dec_inp = V(outp.data.max(1)[1])\n",
    "            if (dec_inp==1).all(): break\n",
    "            if (y is not None) and (random.random()<self.pr_force):\n",
    "                if i>=len(y): break\n",
    "                dec_inp = y[i]\n",
    "        return torch.stack(res)\n",
    "    \n",
    "    def initHidden(self, bs): return V(torch.zeros(self.nl, bs, self.nh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = Seq2SeqRNN_TeacherForcing(fr_vecd, fr_itos, dim_fr_vec, en_vecd, en_itos, dim_en_vec, nh, enlen_90)\n",
    "learn = RNN_Learner(md, SingleModel(to_gpu(rnn)), opt_fn=opt_fn)\n",
    "learn.crit = seq2seq_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(lr, 1, cycle_len=12, use_clr=(20,10), stepper=Seq2SeqStepper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('forcing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attentional model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_t(*sz): return torch.randn(sz)/math.sqrt(sz[0])\n",
    "def rand_p(*sz): return nn.Parameter(rand_t(*sz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqAttnRNN(nn.Module):\n",
    "    def __init__(self, vecs_enc, itos_enc, em_sz_enc, vecs_dec, itos_dec, em_sz_dec, nh, out_sl, nl=2):\n",
    "        super().__init__()\n",
    "        self.emb_enc = create_emb(vecs_enc, itos_enc, em_sz_enc)\n",
    "        self.nl,self.nh,self.out_sl = nl,nh,out_sl\n",
    "        self.gru_enc = nn.GRU(em_sz_enc, nh, num_layers=nl, dropout=0.25)\n",
    "        self.out_enc = nn.Linear(nh, em_sz_dec, bias=False)\n",
    "        self.emb_dec = create_emb(vecs_dec, itos_dec, em_sz_dec)\n",
    "        self.gru_dec = nn.GRU(em_sz_dec, em_sz_dec, num_layers=nl, dropout=0.1)\n",
    "        self.emb_enc_drop = nn.Dropout(0.15)\n",
    "        self.out_drop = nn.Dropout(0.35)\n",
    "        self.out = nn.Linear(em_sz_dec*2, len(itos_dec))\n",
    "        self.out.weight.data = self.emb_dec.weight.data\n",
    "\n",
    "        self.W1 = rand_p(nh, em_sz_dec)\n",
    "        self.l2 = nn.Linear(em_sz_dec, em_sz_dec)\n",
    "        self.l3 = nn.Linear(em_sz_dec+nh, em_sz_dec)\n",
    "        self.V = rand_p(em_sz_dec)\n",
    "\n",
    "    def forward(self, inp, y=None, ret_attn=False):\n",
    "        sl,bs = inp.size()\n",
    "        h = self.initHidden(bs)\n",
    "        emb = self.emb_enc_drop(self.emb_enc(inp))\n",
    "        enc_out, h = self.gru_enc(emb, h)\n",
    "        h = self.out_enc(h)\n",
    "\n",
    "        dec_inp = V(torch.zeros(bs).long())\n",
    "        res,attns = [],[]\n",
    "        w1e = enc_out @ self.W1\n",
    "        for i in range(self.out_sl):\n",
    "            w2h = self.l2(h[-1])\n",
    "            u = F.tanh(w1e + w2h)\n",
    "            a = F.softmax(u @ self.V, 0)\n",
    "            attns.append(a)\n",
    "            Xa = (a.unsqueeze(2) * enc_out).sum(0)\n",
    "            emb = self.emb_dec(dec_inp)\n",
    "            wgt_enc = self.l3(torch.cat([emb, Xa], 1))\n",
    "            \n",
    "            outp, h = self.gru_dec(wgt_enc.unsqueeze(0), h)\n",
    "            outp = self.out(self.out_drop(outp[0]))\n",
    "            res.append(outp)\n",
    "            dec_inp = V(outp.data.max(1)[1])\n",
    "            if (dec_inp==1).all(): break\n",
    "            if (y is not None) and (random.random()<self.pr_force):\n",
    "                if i>=len(y): break\n",
    "                dec_inp = y[i]\n",
    "\n",
    "        res = torch.stack(res)\n",
    "        if ret_attn: res = res,torch.stack(attns)\n",
    "        return res\n",
    "\n",
    "    def initHidden(self, bs): return V(torch.zeros(self.nl, bs, self.nh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = Seq2SeqAttnRNN(fr_vecd, fr_itos, dim_fr_vec, en_vecd, en_itos, dim_en_vec, nh, enlen_90)\n",
    "learn = RNN_Learner(md, SingleModel(to_gpu(rnn)), opt_fn=opt_fn)\n",
    "learn.crit = seq2seq_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=2e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "learn.fit(lr, 1, cycle_len=15, use_clr=(20,10), stepper=Seq2SeqStepper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('attn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('attn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x,y = next(iter(val_dl))\n",
    "probs,attns = learn.model(V(x),ret_attn=True)\n",
    "preds = to_np(probs.max(2)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for i in range(180,190):\n",
    "    print(' '.join([fr_itos[o] for o in x[:,i] if o != 1]))\n",
    "    print(' '.join([en_itos[o] for o in y[:,i] if o != 1]))\n",
    "    print(' '.join([en_itos[o] for o in preds[:,i] if o!=1]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "attn = to_np(attns[...,180])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 3, figsize=(15, 10))\n",
    "for i,ax in enumerate(axes.flat):\n",
    "    ax.plot(attn[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqRNN_All(nn.Module):\n",
    "    def __init__(self, vecs_enc, itos_enc, em_sz_enc, vecs_dec, itos_dec, em_sz_dec, nh, out_sl, nl=2):\n",
    "        super().__init__()\n",
    "        self.emb_enc = create_emb(vecs_enc, itos_enc, em_sz_enc)\n",
    "        self.nl,self.nh,self.out_sl = nl,nh,out_sl\n",
    "        self.gru_enc = nn.GRU(em_sz_enc, nh, num_layers=nl, dropout=0.25, bidirectional=True)\n",
    "        self.out_enc = nn.Linear(nh*2, em_sz_dec, bias=False)\n",
    "        self.drop_enc = nn.Dropout(0.25)\n",
    "        self.emb_dec = create_emb(vecs_dec, itos_dec, em_sz_dec)\n",
    "        self.gru_dec = nn.GRU(em_sz_dec, em_sz_dec, num_layers=nl, dropout=0.1)\n",
    "        self.emb_enc_drop = nn.Dropout(0.15)\n",
    "        self.out_drop = nn.Dropout(0.35)\n",
    "        self.out = nn.Linear(em_sz_dec, len(itos_dec))\n",
    "        self.out.weight.data = self.emb_dec.weight.data\n",
    "\n",
    "        self.W1 = rand_p(nh*2, em_sz_dec)\n",
    "        self.l2 = nn.Linear(em_sz_dec, em_sz_dec)\n",
    "        self.l3 = nn.Linear(em_sz_dec+nh*2, em_sz_dec)\n",
    "        self.V = rand_p(em_sz_dec)\n",
    "\n",
    "    def forward(self, inp, y=None):\n",
    "        sl,bs = inp.size()\n",
    "        h = self.initHidden(bs)\n",
    "        emb = self.emb_enc_drop(self.emb_enc(inp))\n",
    "        enc_out, h = self.gru_enc(emb, h)\n",
    "        h = h.view(2,2,bs,-1).permute(0,2,1,3).contiguous().view(2,bs,-1)\n",
    "        h = self.out_enc(self.drop_enc(h))\n",
    "\n",
    "        dec_inp = V(torch.zeros(bs).long())\n",
    "        res,attns = [],[]\n",
    "        w1e = enc_out @ self.W1\n",
    "        for i in range(self.out_sl):\n",
    "            w2h = self.l2(h[-1])\n",
    "            u = F.tanh(w1e + w2h)\n",
    "            a = F.softmax(u @ self.V, 0)\n",
    "            attns.append(a)\n",
    "            Xa = (a.unsqueeze(2) * enc_out).sum(0)\n",
    "            emb = self.emb_dec(dec_inp)\n",
    "            wgt_enc = self.l3(torch.cat([emb, Xa], 1))\n",
    "            \n",
    "            outp, h = self.gru_dec(wgt_enc.unsqueeze(0), h)\n",
    "            outp = self.out(self.out_drop(outp[0]))\n",
    "            res.append(outp)\n",
    "            dec_inp = V(outp.data.max(1)[1])\n",
    "            if (dec_inp==1).all(): break\n",
    "            if (y is not None) and (random.random()<self.pr_force):\n",
    "                if i>=len(y): break\n",
    "                dec_inp = y[i]\n",
    "        return torch.stack(res)\n",
    "\n",
    "    def initHidden(self, bs): return V(torch.zeros(self.nl*2, bs, self.nh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = Seq2SeqRNN_All(fr_vecd, fr_itos, dim_fr_vec, en_vecd, en_itos, dim_en_vec, nh, enlen_90)\n",
    "learn = RNN_Learner(md, SingleModel(to_gpu(rnn)), opt_fn=opt_fn)\n",
    "learn.crit = seq2seq_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "learn.fit(lr, 1, cycle_len=15, use_clr=(20,10), stepper=Seq2SeqStepper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(iter(val_dl))\n",
    "probs = learn.model(V(x))\n",
    "preds = to_np(probs.max(2)[1])\n",
    "\n",
    "for i in range(180,190):\n",
    "    print(' '.join([fr_itos[o] for o in x[:,i] if o != 1]))\n",
    "    print(' '.join([en_itos[o] for o in y[:,i] if o != 1]))\n",
    "    print(' '.join([en_itos[o] for o in preds[:,i] if o!=1]))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fastai]",
   "language": "python",
   "name": "conda-env-fastai-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "253px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
