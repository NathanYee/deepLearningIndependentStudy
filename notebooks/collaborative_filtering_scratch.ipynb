{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fastai.learner'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2d197bb261d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfastai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearner\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfastai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumn_data\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'fastai.learner'"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from fastai.learner import *\n",
    "from fastai.column_data import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data: http://files.grouplens.org/datasets/movielens/ml-latest-small.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/movie-lens/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv(os.path.join(path, \"ratings.csv\"))\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv(os.path.join(path, \"movies.csv\"))\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_idxs = get_cv_idxs(len(ratings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative filtering scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dot product example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = T([[1,2],[3,4]])\n",
    "b = T([[2,2],[10,10]])\n",
    "a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(a*b).sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DotProduct(nn.Module):\n",
    "    def forward(self, u, m):\n",
    "        return (u*m).sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DotProduct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dot product collaborative filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_uniq = ratings.userId.unique()\n",
    "user2idx = {u_id:i for i,u_id in enumerate(u_uniq)}\n",
    "ratings.userId = ratings.userId.apply(lambda x: user2idx[x])\n",
    "\n",
    "m_uniq = ratings.movieId.unique()\n",
    "movie2idx = {m_id:i for i,m_id in enumerate(m_uniq)}\n",
    "ratings.movieId = ratings.movieId.apply(lambda x: movie2idx[x])\n",
    "\n",
    "n_users  = ratings.userId.nunique()\n",
    "n_movies = ratings.movieId.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingDot(nn.Module):\n",
    "    def __init__(self, n_users, n_movies, n_factors):\n",
    "        \"\"\"\n",
    "        :param n_users: number of unique users\n",
    "        :type  n_users: int\n",
    "        \n",
    "        :param n_movies: number of unique movies\n",
    "        :type  n_users: int\n",
    "        \n",
    "        :param n_factors: size of embedding matrix for users and movies\n",
    "        :type  n_factors: int\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.u = nn.Embedding(n_users, n_factors)\n",
    "        self.m = nn.Embedding(n_movies, n_factors)\n",
    "        self.u.weight.data.uniform_(0,0.05)\n",
    "        self.m.weight.data.uniform_(0,0.05)\n",
    "        \n",
    "    def forward(self, cats, conts):\n",
    "        \"\"\"\n",
    "        :param cats: the categorical indices for users and movies\n",
    "        :type  cats: ndarray\n",
    "        :param conts: continuous values, does not apply here but data generator requires it\n",
    "        \"\"\"\n",
    "        users,movies = cats[:,0],cats[:,1]\n",
    "        u,m = self.u(users),self.m(movies)\n",
    "        return (u*m).sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ratings.drop(['rating', 'timestamp'], axis=1)\n",
    "y = ratings['rating'].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ColumnarModelData.from_data_frame(path, val_idxs, x, y, ['userId', 'movieId'], 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_factors = 40\n",
    "model = EmbeddingDot(n_users, n_movies, n_factors).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd = 1e-5\n",
    "lr = .1\n",
    "opt = optim.SGD(model.parameters(), lr=lr, weight_decay=wd, momentum=.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit(model, data, 3, opt, F.mse_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_lrs(opt, 0.01)\n",
    "fit(model, data, 3, opt, F.mse_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_rating, max_rating = ratings.rating.min(), ratings.rating.max()\n",
    "min_rating, max_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embed(ni, nf):\n",
    "    \"\"\"\n",
    "    :param ni: number of unique indices\n",
    "    :param nf: number of factors\n",
    "    \"\"\"\n",
    "    embed = nn.Embedding(ni, nf)\n",
    "    embed.weight.data.uniform_(-0.02, 0.02)\n",
    "    return embed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingDotBias(nn.Module):\n",
    "    def __init__(self, n_users, n_items, n_factors, min_rating, max_rating):\n",
    "        super().__init__()\n",
    "        self.min_rating = min_rating\n",
    "        self.max_rating = max_rating\n",
    "        embeds = [(n_users, n_factors), (n_users,1), (n_items, n_factors), (n_items,1)]\n",
    "        (self.u, self.ub, self.m, self.mb) = [get_embed(*e) for e in embeds]\n",
    "    \n",
    "    def forward(self, cats, _):\n",
    "        users,items = cats[:,0],cats[:,1]\n",
    "        res = (self.u(users)* self.m(items)).sum(1)\n",
    "        res = res + self.ub(users).squeeze() + self.mb(items).squeeze()\n",
    "        res = F.sigmoid(res) * (max_rating-min_rating) + min_rating\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd=2e-4\n",
    "model = EmbeddingDotBias(n_users, n_movies, n_factors, min_rating, max_rating).cuda()\n",
    "opt = optim.SGD(model.parameters(), 1e-1, weight_decay=wd, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit(model, data, 3, opt, F.mse_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingNet(nn.Module):\n",
    "    def __init__(self, n_users, n_items, n_factors, nh=10, p1=0.5, p2=0.5):\n",
    "        super().__init__()\n",
    "        embeds = [(n_users, n_factors), (n_users,1), (n_items, n_factors), (n_items,1)]\n",
    "        (self.u, self.ub, self.m, self.mb) = [get_embed(*e) for e in embeds]\n",
    "        self.lin1 = nn.Linear(n_factors*2, nh)\n",
    "        self.lin2 = nn.Linear(nh, 1)\n",
    "        self.drop1 = nn.Dropout(p1)\n",
    "        self.drop2 = nn.Dropout(p2)\n",
    "        \n",
    "    def forward(self, cats, conts):\n",
    "        users,items = cats[:,0],cats[:,1]\n",
    "        x = self.drop1(torch.cat([self.u(users),self.m(items)], dim=1))\n",
    "        x = self.drop2(F.relu(self.lin1(x)))\n",
    "        x = self.lin2(x) + self.ub(users) + self.mb(items)\n",
    "        return F.sigmoid(x) * (max_rating-min_rating+1) + min_rating-0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd=1e-6\n",
    "model = EmbeddingNet(n_users, n_movies, n_factors=40, nh=10).cuda()\n",
    "opt = optim.Adam(model.parameters(), 1e-3, weight_decay=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit(model, data, 3, opt, F.mse_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_lrs(opt, 1e-4)\n",
    "fit(model, data, 3, opt, F.mse_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(0.77328)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fastai]",
   "language": "python",
   "name": "conda-env-fastai-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
